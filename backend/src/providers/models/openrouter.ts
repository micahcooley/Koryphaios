import type { ModelDef } from "@koryphaios/shared";

export const OpenRouterModels: ModelDef[] = [
  {
    id: "openrouter.gpt-5.2",
    name: "OpenRouter – GPT 5.2",
    provider: "openrouter",
    apiModelId: "openai/gpt-5.2",
    contextWindow: 400_000,
    maxOutputTokens: 128_000,
    costPerMInputTokens: 1.25,
    costPerMOutputTokens: 10.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "openrouter.claude-4.5-sonnet",
    name: "OpenRouter – Claude 4.5 Sonnet",
    provider: "openrouter",
    apiModelId: "anthropic/claude-4.5-sonnet",
    contextWindow: 400_000,
    maxOutputTokens: 128_000,
    costPerMInputTokens: 3.0,
    costPerMOutputTokens: 15.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "openrouter.gemini-3-pro",
    name: "OpenRouter – Gemini 3 Pro",
    provider: "openrouter",
    apiModelId: "google/gemini-3-pro",
    contextWindow: 1_000_000,
    maxOutputTokens: 128_000,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "openrouter.gemini-3-flash",
    name: "OpenRouter – Gemini 3 Flash",
    provider: "openrouter",
    apiModelId: "google/gemini-3-flash",
    contextWindow: 1_000_000,
    maxOutputTokens: 64_000,
    tier: "fast",
  },

  // Legacy
  {
    id: "openrouter.gpt-4o",
    name: "OpenRouter – GPT 4o (Legacy)",
    provider: "openrouter",
    apiModelId: "openai/gpt-4o",
    contextWindow: 128_000,
    maxOutputTokens: 4_096,
    tier: "flagship",
  },
];
