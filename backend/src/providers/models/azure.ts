import type { ModelDef } from "@koryphaios/shared";

export const AzureModels: ModelDef[] = [
  {
    id: "azure.gpt-4.1",
    name: "Azure OpenAI – GPT 4.1",
    provider: "azure",
    apiModelId: "gpt-4.1",
    contextWindow: 1_047_576,
    maxOutputTokens: 20_000,
    costPerMInputTokens: 2.0,
    costPerMOutputTokens: 8.0,
    costPerMInputCached: 0.50,
    costPerMOutputCached: 0.0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "azure.gpt-4.1-mini",
    name: "Azure OpenAI – GPT 4.1 mini",
    provider: "azure",
    apiModelId: "gpt-4.1-mini",
    contextWindow: 200_000,
    maxOutputTokens: 20_000,
    costPerMInputTokens: 0.40,
    costPerMOutputTokens: 1.60,
    costPerMInputCached: 0.10,
    costPerMOutputCached: 0.0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "azure.gpt-4.1-nano",
    name: "Azure OpenAI – GPT 4.1 nano",
    provider: "azure",
    apiModelId: "gpt-4.1-nano",
    contextWindow: 1_047_576,
    maxOutputTokens: 20_000,
    costPerMInputTokens: 0.10,
    costPerMOutputTokens: 0.40,
    costPerMInputCached: 0.025,
    costPerMOutputCached: 0.0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "cheap",
  },
  {
    id: "azure.gpt-4.5-preview",
    name: "Azure OpenAI – GPT 4.5 preview",
    provider: "azure",
    apiModelId: "gpt-4.5-preview",
    contextWindow: 128_000,
    maxOutputTokens: 15_000,
    costPerMInputTokens: 75.0,
    costPerMOutputTokens: 150.0,
    costPerMInputCached: 37.50,
    costPerMOutputCached: 0.0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "azure.gpt-4o",
    name: "Azure OpenAI – GPT-4o",
    provider: "azure",
    apiModelId: "gpt-4o",
    contextWindow: 128_000,
    maxOutputTokens: 4_096,
    costPerMInputTokens: 2.50,
    costPerMOutputTokens: 10.0,
    costPerMInputCached: 1.25,
    costPerMOutputCached: 0.0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "azure.gpt-4o-mini",
    name: "Azure OpenAI – GPT-4o mini",
    provider: "azure",
    apiModelId: "gpt-4o-mini",
    contextWindow: 128_000,
    maxOutputTokens: 4_096,
    costPerMInputTokens: 0.15,
    costPerMOutputTokens: 0.60,
    costPerMInputCached: 0.075,
    costPerMOutputCached: 0.0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "azure.o1",
    name: "Azure OpenAI – O1",
    provider: "azure",
    apiModelId: "o1",
    contextWindow: 200_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 15.0,
    costPerMOutputTokens: 60.0,
    costPerMInputCached: 7.50,
    costPerMOutputCached: 0.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "reasoning",
  },
  {
    id: "azure.o1-mini",
    name: "Azure OpenAI – O1 mini",
    provider: "azure",
    apiModelId: "o1-mini",
    contextWindow: 128_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 1.10,
    costPerMOutputTokens: 4.40,
    costPerMInputCached: 0.55,
    costPerMOutputCached: 0.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "reasoning",
  },
  {
    id: "azure.o3",
    name: "Azure OpenAI – O3",
    provider: "azure",
    apiModelId: "o3",
    contextWindow: 200_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 10.0,
    costPerMOutputTokens: 40.0,
    costPerMInputCached: 2.50,
    costPerMOutputCached: 0.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "reasoning",
  },
  {
    id: "azure.o3-mini",
    name: "Azure OpenAI – O3 mini",
    provider: "azure",
    apiModelId: "o3-mini",
    contextWindow: 200_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 1.10,
    costPerMOutputTokens: 4.40,
    costPerMInputCached: 0.55,
    costPerMOutputCached: 0.0,
    canReason: true,
    supportsAttachments: false,
    supportsStreaming: true,
    tier: "reasoning",
  },
  {
    id: "azure.o4-mini",
    name: "Azure OpenAI – O4 mini",
    provider: "azure",
    apiModelId: "o4-mini",
    contextWindow: 128_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 1.10,
    costPerMOutputTokens: 4.40,
    costPerMInputCached: 0.275,
    costPerMOutputCached: 0.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "reasoning",
  },
];
