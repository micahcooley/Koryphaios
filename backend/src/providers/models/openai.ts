import type { ModelDef } from "@koryphaios/shared";

export const OpenAIModels: ModelDef[] = [
  // Current Models (2025-2026)
  {
    id: "gpt-5.3-codex",
    name: "GPT 5.3 Codex",
    provider: "openai",
    apiModelId: "gpt-5.3-codex",
    contextWindow: 500_000,
    maxOutputTokens: 128_000,
    costPerMInputTokens: 1.50,
    costPerMOutputTokens: 12.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "gpt-5.2-pro",
    name: "GPT 5.2 Pro",
    provider: "openai",
    apiModelId: "gpt-5.2-pro",
    contextWindow: 400_000,
    maxOutputTokens: 128_000,
    costPerMInputTokens: 1.25,
    costPerMOutputTokens: 10.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "gpt-5.2",
    name: "GPT 5.2",
    provider: "openai",
    apiModelId: "gpt-5.2",
    contextWindow: 400_000,
    maxOutputTokens: 128_000,
    costPerMInputTokens: 1.25,
    costPerMOutputTokens: 10.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "gpt-5.2-instant",
    name: "GPT-5.2 Instant",
    provider: "openai",
    apiModelId: "gpt-5.2-instant",
    contextWindow: 400_000,
    maxOutputTokens: 64_000,
    costPerMInputTokens: 0.50,
    costPerMOutputTokens: 2.50,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "gpt-5-mini",
    name: "GPT 5 mini",
    provider: "openai",
    apiModelId: "gpt-5-mini",
    contextWindow: 128_000,
    maxOutputTokens: 16_384,
    costPerMInputTokens: 0.15,
    costPerMOutputTokens: 0.60,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "cheap",
  },
  {
    id: "gpt-5-nano",
    name: "GPT 5 nano",
    provider: "openai",
    apiModelId: "gpt-5-nano",
    contextWindow: 128_000,
    maxOutputTokens: 4_096,
    costPerMInputTokens: 0.05,
    costPerMOutputTokens: 0.15,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "cheap",
  },

  // Legacy Models (Retired Feb 2026)
  {
    id: "gpt-4.1",
    name: "GPT 4.1 (Legacy)",
    provider: "openai",
    apiModelId: "gpt-4.1",
    contextWindow: 128_000,
    maxOutputTokens: 16_384,
    costPerMInputTokens: 5.0,
    costPerMOutputTokens: 15.0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
  {
    id: "o4-mini",
    name: "o4 mini (Legacy)",
    provider: "openai",
    apiModelId: "o4-mini",
    contextWindow: 128_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 1.10,
    costPerMOutputTokens: 4.40,
    costPerMInputCached: 0.275,
    costPerMOutputCached: 0.0,
    canReason: true,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "reasoning",
  },
  {
    id: "gpt-4o",
    name: "GPT 4o (Legacy)",
    provider: "openai",
    apiModelId: "gpt-4o",
    contextWindow: 128_000,
    maxOutputTokens: 4_096,
    costPerMInputTokens: 5.0,
    costPerMOutputTokens: 15.0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "flagship",
  },
];
