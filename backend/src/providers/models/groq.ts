import type { ModelDef } from "@koryphaios/shared";

export const GroqModels: ModelDef[] = [
  {
    id: "qwen-qwq-32b",
    name: "Qwen Qwq",
    provider: "groq",
    apiModelId: "qwen-qwq-32b",
    contextWindow: 128_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 0.29,
    costPerMOutputTokens: 0.39,
    costPerMInputCached: 0.275,
    costPerMOutputCached: 0.0,
    canReason: false,
    supportsAttachments: false,
    supportsStreaming: true,
    tier: "cheap",
  },
  {
    id: "meta-llama/llama-4-scout-17b-16e-instruct",
    name: "Llama 4 Scout",
    provider: "groq",
    apiModelId: "meta-llama/llama-4-scout-17b-16e-instruct",
    contextWindow: 128_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 0.11,
    costPerMOutputTokens: 0.34,
    costPerMInputCached: 0,
    costPerMOutputCached: 0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "meta-llama/llama-4-maverick-17b-128e-instruct",
    name: "Llama 4 Maverick",
    provider: "groq",
    apiModelId: "meta-llama/llama-4-maverick-17b-128e-instruct",
    contextWindow: 128_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 0.20,
    costPerMOutputTokens: 0.20,
    costPerMInputCached: 0,
    costPerMOutputCached: 0,
    canReason: false,
    supportsAttachments: true,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "llama-3.3-70b-versatile",
    name: "Llama 3.3 70B Versatile",
    provider: "groq",
    apiModelId: "llama-3.3-70b-versatile",
    contextWindow: 128_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 0.59,
    costPerMOutputTokens: 0.79,
    costPerMInputCached: 0,
    costPerMOutputCached: 0,
    canReason: false,
    supportsAttachments: false,
    supportsStreaming: true,
    tier: "fast",
  },
  {
    id: "deepseek-r1-distill-llama-70b",
    name: "DeepSeek R1 Distill Llama 70B",
    provider: "groq",
    apiModelId: "deepseek-r1-distill-llama-70b",
    contextWindow: 128_000,
    maxOutputTokens: 50_000,
    costPerMInputTokens: 0.75,
    costPerMOutputTokens: 0.99,
    costPerMInputCached: 0,
    costPerMOutputCached: 0,
    canReason: true,
    supportsAttachments: false,
    supportsStreaming: true,
    tier: "reasoning",
  },
];
